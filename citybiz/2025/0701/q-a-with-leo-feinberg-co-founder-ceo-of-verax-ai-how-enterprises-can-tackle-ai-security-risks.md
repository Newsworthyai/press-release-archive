# Q&amp;A with Leo Feinberg, Co-founder &amp; CEO of Verax AI: How Enterprises Can Tackle AI Security Risks

Leo Feinberg is CEO and Co-founder at Verax AI, a leader in enabling the safe and responsible adoption of AI for enterprise use. The company enables large organizations to fully harness the productivity benefits of AI technologies, while mitigating the security and trust issues associated with their adoption. Leo has deep experience in the trust, transparency and information security space, having launched and scaled several successful technology startups, including CloudEndure, which was acquired by AWS in 2019 for $250 million.

 As AI adoption accelerates across industries, what do you see as the most pressing risks companies face today?

 We see two main risks. The first is that not all AI tools are created equal, and it is still very difficult to figure out which AI tools are a good fit for a company’s specific requirements in each use case. As a result, many AI solutions are built, evaluated and even purchased very quickly, only to disappoint the companies using them and leading them to doubt the overall value of AI. However, with the right tool – usually developed by a vendor specializing in AI – the benefits can already be significant, even today, when AI is still in its infancy.

 The second risk is data leakage into third party AI tools. These tools encourage users, more than ever before, to send large volumes of information into them, with higher volumes often translating into greater benefits. However, much of the information corporate employees send to these tools is sensitive or confidential, causing arguably the largest data leak to date, one that traditional security tools are not equipped to handle.

 Where do you see the biggest blind spots in how organizations are approaching AI threats?

 Many organizations allow the use of AI (or at least of specific AI tools), without having any automated controls in place to prevent data leakage. Instead, they rely on basic methods such as employee training and pop up banners whenever an employee attempts to use AI. Unfortunately, it has been demonstrated time and time again that these methods are ineffective when not complimented by automated enforcement.

 In many cases, companies are aware of the risks of data leakage into AI. However, they often don’t address them properly, instead prioritizing tackling other more traditional security challenges within the organization.

 For this exact reason, at Verax AI we have developed a solution – Verax Protect – that enables enterprises to automatically enforce corporate AI policies across all employee devices, from browser and applications to desktop and mobile. This enables them to reap the full productivity benefits of AI tools like ChatGPT and Claude safely and securely.

 What strategies do you think companies should adopt to safeguard themselves from these emerging risks?

 My suggestion would be to either allow employees to choose the AI tools they believe work best or to choose tools at the company level using the same criteria. Once a tool has been chosen, companies should implement solutions that automatically block or sanitize AI usage that could violate company policies or expose sensitive information. The combination of these two measures should provide the best risk/reward ratio, offering lower risks and higher rewards.

 You’ve just launched your latest product Verax Protect – what sets it apart from other solutions on the market?

 Verax Protect has been specifically built to accommodate even regulated companies with the strictest security, privacy and compliance requirements. The AI security and privacy market is quite young (just like modern AI itself), and most efforts currently focus on the “low-hanging fruit”, such as SMEs and AI-native enterprises. However, more traditional organizations, especially those in regulated industries, face even greater challenges related to data leakage, privacy and security when they allow employees to use third-party AI tools. Verax Protect has been designed to meet the full range of AI privacy needs for companies of all types and sizes.

 How do you see the cybersecurity industry evolving more broadly in light of these new threats?

 The cybersecurity industry usually evolves most rapidly in response to the equally fast evolution of cybersecurity threats. With the rise of AI, there has been an overnight surge in new types of security risks, and the cybersecurity industry is still working to catch up with them – as these risks continue to grow. Therefore, I envision that cybersecurity companies will rise to the occasion over the next 12-24 months and will provide the necessary safeguards and mitigations in light of the increasing AI-related risks.

 How do you see the role of AI in the workplace evolving in the coming years?

 I am a strong believer that AI can significantly improve and optimize almost any workflow in the workplace, and it’s simply a matter of having enough vendors invest the necessary resources to develop each of these AI improvements. In my opinion, once AI has been introduced into enough business-critical areas, it will enhance the effectiveness and productivity of companies on a scale never seen before.

 What does the future hold for Verax AI? Where do you plan to take the company in the next 12 months?

 AI adoption in enterprises is growing very quickly, and the risks associated with it not only increase, but also evolve and expand with each new workflow enhanced by AI. At Verax, we need to constantly stay one step ahead to be able to prevent and mitigate the AI risks of tomorrow, and not just those of today. For example, more and more enterprises are centrally purchasing licenses for third- party AI-generated coding tools such as Cursor and Windsurf. While these tools deliver huge productivity gains for engineers, they also expose companies to risks such as malicious code and code that violates third-party licenses. Use cases like this will continue to be added to the ones Verax Protect already supports, until Verax becomes a fully-fledged one-stop-shop for everything related to the security, privacy and safety of interactions between employees and third-party AI tools.

 The post Q&A with Leo Feinberg, Co-founder & CEO of Verax AI: How Enterprises Can Tackle AI Security Risks appeared first on citybiz. 

---

[Original/Source Press Release](https://www.citybiz.co/article/713091/qa-with-leo-feinberg-co-founder-ceo-of-verax-ai-how-enterprises-can-tackle-ai-security-risks/)
                    

[Newsramp.com TLDR](https://newsramp.com/curated-news/verax-ai-ceo-on-tackling-ai-security-risks-in-enterprises/a9afd6ed08cef76dd86b3f697a0b2392) 

 



[Reddit Post](https://www.reddit.com/r/newsramp/comments/1lpqg7m/verax_ai_ceo_on_tackling_ai_security_risks_in/) 



![Blockchain Registration](https://cdn.newsramp.app/citybiz/qrcode/257/2/yogaVOPm.webp)